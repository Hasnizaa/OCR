{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO2ybP5Ak4Ao43NTkMWSM27",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasnizaa/OCR/blob/main/DSP2%20(FYP2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the libraries"
      ],
      "metadata": {
        "id": "SJhC_5FRfasX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!pip install tesseract\n"
      ],
      "metadata": {
        "id": "PyLE-gEWqebb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "WO2nzufwTA4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "id": "r1K_IewmYo4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "KYPJ-TfWbgzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfE9u3YNfE1L"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the Tesseract executable for Google Colab\n",
        "# Use the correct path which is usually /usr/bin/tesseract in Colab\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'"
      ],
      "metadata": {
        "id": "lx_ftNfVtvNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the above path doesn't work, try this alternative:\n",
        "#pytesseract.pytesseract.tesseract_cmd = r'/usr/local/bin/tesseract'"
      ],
      "metadata": {
        "id": "LpiT75bZWFfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Tesseract version to ensure it's installed and accessible\n",
        "print(pytesseract.get_tesseract_version())"
      ],
      "metadata": {
        "id": "AdBzgLg2WN2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA 1"
      ],
      "metadata": {
        "id": "4NZjnx3Y0pyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# List of image file paths\n",
        "image_files = [\n",
        "    'data3.jpg',\n",
        "    'data4(1).jpg',\n",
        "    'data5.jpg',\n",
        "    'data6.jpg',\n",
        "    'data7.jpg',\n",
        "    'data8.jpg',\n",
        "    'data9(1).jpg',\n",
        "    'data10(1).jpg',\n",
        "    'data11.jpg',\n",
        "    'data12.jpg',\n",
        "    'data13.jpg',\n",
        "    'data14.jpg',\n",
        "    'data15.jpg',\n",
        "    'data16.jpg'\n",
        "]\n",
        "\n",
        "# List to store extracted text from each image\n",
        "extracted_texts = []\n",
        "\n",
        "# Iterate over the list of image files\n",
        "for img_path in image_files:\n",
        "    # Open the image file\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Perform OCR on the image\n",
        "    text = pytesseract.image_to_string(img)\n",
        "\n",
        "    # Append the extracted text to the list\n",
        "    extracted_texts.append((img_path, text))\n",
        "\n",
        "# Print the extracted texts\n",
        "for img_path, text in extracted_texts:\n",
        "    print(f\"Text from {img_path}:\\n{text}\\n\")"
      ],
      "metadata": {
        "id": "pQioPEYDDvuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Define the pattern to extract transaction details, allowing for optional merchant name\n",
        "transaction_pattern = re.compile(\n",
        "    r'(\\d{2}/\\d{2}/\\d{2})\\s+\\|\\s+(.*?)\\s+([+-]?\\d{1,3}(,\\d{3})*(\\.\\d+)?)([+-])?\\s+([\\d,.]+)(\\n([A-Za-z\\s]+))?'\n",
        ")\n",
        "\n",
        "# Initialize a list to store extracted transactions\n",
        "transactions = []\n",
        "\n",
        "# Process each extracted text entry\n",
        "for img_path, extracted_text in extracted_texts:\n",
        "    # Use regex to find all matches\n",
        "    for match in transaction_pattern.finditer(extracted_text):\n",
        "        entry_date, description, amount, _, _, sign, balance, _, merchant = match.groups()\n",
        "\n",
        "        # Clean up the extracted data\n",
        "        amount = amount.replace(',', '')\n",
        "        balance = balance.replace(',', '')\n",
        "\n",
        "        # Determine debit or credit\n",
        "        debit = 0.0\n",
        "        credit = 0.0\n",
        "        if sign == '+':\n",
        "            credit = float(amount)\n",
        "        elif sign == '-':\n",
        "            debit = float(amount)\n",
        "        else:  # If no sign, assume debit\n",
        "            debit = float(amount)\n",
        "\n",
        "        # Notes: Any additional description from the main description field\n",
        "        notes = description.strip()\n",
        "\n",
        "        # If there's no merchant name captured, set it to \"UNKNOWN\"\n",
        "        merchant = merchant.strip() if merchant else \"UNKNOWN\"\n",
        "\n",
        "        # Append transaction details\n",
        "        transactions.append([entry_date, merchant, notes, debit, credit, float(balance)])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(transactions, columns=['Date', 'Merchant', 'PaymentType', 'Debit', 'Credit', 'Balance'])\n",
        "\n",
        "# Display the DataFrame\n",
        "df\n"
      ],
      "metadata": {
        "id": "HoBmdt0Ca5y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = 'data1.jpg'\n",
        "image2 = 'data2.jpg'"
      ],
      "metadata": {
        "id": "4CPmxPEp4Aa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform OCR on the preprocessed image\n",
        "extractedInformation1 = pytesseract.image_to_string(image1)\n",
        "print(extractedInformation1)"
      ],
      "metadata": {
        "id": "QOFZUNfbzHBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Define the pattern to extract transaction details, allowing for optional merchant name\n",
        "transaction_pattern = re.compile(\n",
        "    r'(\\d{2}/\\d{2}/\\d{2})\\s+\\|\\s+(.*?)\\s+([+-]?\\d{1,3}(,\\d{3})*(\\.\\d+)?)([+-])?\\s+([\\d,.]+)(\\n([A-Za-z\\s]+))?'\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize a list to store extracted transactions\n",
        "transactions = []\n",
        "\n",
        "# Use regex to find all matches\n",
        "for match in transaction_pattern.finditer(extractedInformation1):\n",
        "    entry_date, description, amount, _, _, sign, balance, _, merchant = match.groups()\n",
        "\n",
        "    # Clean up the extracted data\n",
        "    amount = amount.replace(',', '')\n",
        "    balance = balance.replace(',', '')\n",
        "\n",
        "    # Determine debit or credit\n",
        "    debit = 0.0\n",
        "    credit = 0.0\n",
        "    if sign == '+':\n",
        "        credit = float(amount)\n",
        "    elif sign == '-':\n",
        "        debit = float(amount)\n",
        "    else:  # If no sign, assume debit\n",
        "        debit = float(amount)\n",
        "\n",
        "    # Notes: Any additional description from the main description field\n",
        "    notes = description.strip()\n",
        "\n",
        "    # If there's no merchant name captured, set it to \"UNKNOWN\"\n",
        "    merchant = merchant.strip() if merchant else \"UNKNOWN\"\n",
        "\n",
        "    # Append transaction details\n",
        "    transactions.append([entry_date, merchant, notes, debit, credit, float(balance)])\n",
        "\n",
        "# Create a DataFrame\n",
        "df1 = pd.DataFrame(transactions, columns=['Date', 'Merchant', 'PaymentType', 'Debit', 'Credit', 'Balance'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df1)\n"
      ],
      "metadata": {
        "id": "INC479hLkXM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform OCR on the preprocessed image\n",
        "extractedInformation2 = pytesseract.image_to_string(image2)\n",
        "print(extractedInformation2)"
      ],
      "metadata": {
        "id": "lofqGodBk-Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Define the pattern to extract transaction details, allowing for optional merchant name\n",
        "transaction_pattern = re.compile(\n",
        "    r'(\\d{2}/\\d{2}/\\d{2})\\s+\\|\\s+(.*?)\\s+([+-]?\\d{1,3}(,\\d{3})*(\\.\\d+)?)([+-])?\\s+([\\d,.]+)(\\n([A-Za-z\\s]+))?'\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize a list to store extracted transactions\n",
        "transactions = []\n",
        "\n",
        "# Use regex to find all matches\n",
        "for match in transaction_pattern.finditer(extractedInformation2):\n",
        "    entry_date, description, amount, _, _, sign, balance, _, merchant = match.groups()\n",
        "\n",
        "    # Clean up the extracted data\n",
        "    amount = amount.replace(',', '')\n",
        "    balance = balance.replace(',', '')\n",
        "\n",
        "    # Determine debit or credit\n",
        "    debit = 0.0\n",
        "    credit = 0.0\n",
        "    if sign == '+':\n",
        "        credit = float(amount)\n",
        "    elif sign == '-':\n",
        "        debit = float(amount)\n",
        "    else:  # If no sign, assume debit\n",
        "        debit = float(amount)\n",
        "\n",
        "    # Notes: Any additional description from the main description field\n",
        "    notes = description.strip()\n",
        "\n",
        "    # If there's no merchant name captured, set it to \"UNKNOWN\"\n",
        "    merchant = merchant.strip() if merchant else \"UNKNOWN\"\n",
        "\n",
        "    # Append transaction details\n",
        "    transactions.append([entry_date, merchant, notes, debit, credit, float(balance)])\n",
        "\n",
        "# Create a DataFrame\n",
        "df2 = pd.DataFrame(transactions, columns=['Date', 'Merchant', 'PaymentType', 'Debit', 'Credit', 'Balance'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df2)\n"
      ],
      "metadata": {
        "id": "Vd9v5Oloq_GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the DataFrames\n",
        "merged_df = pd.concat([df1, df2, df], ignore_index=True)\n",
        "\n",
        "merged_df"
      ],
      "metadata": {
        "id": "Q2QzTHz_NhkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new column for person_id\n",
        "merged_df['Person'] = 'A'"
      ],
      "metadata": {
        "id": "PBHPfgWilIJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.isna().sum()"
      ],
      "metadata": {
        "id": "sNbRoe_lf_3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
        "merged_df"
      ],
      "metadata": {
        "id": "MgII-cT-ir_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payment_types = merged_df['PaymentType']\n",
        "payment_types.unique()"
      ],
      "metadata": {
        "id": "-C1uKktKkz7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of replacements\n",
        "payment_type_replacements = {\n",
        "    'SNHO123': 'Stock Transaction',\n",
        "    'SNHO12)': 'Stock Transaction',\n",
        "    'SALE DEBIT': 'Card Payment',\n",
        "    'FPX PAYMENT FR A/': 'Online Payment',\n",
        "    'IBK FUND TFR FR A/C': 'Fund Transfer In (IBK)',\n",
        "    'FUND TRANSFER TO A/': 'Fund Transfer Out',\n",
        "    'PAYMENT VIA MYDEBIT': 'MyDebit Payment',\n",
        "    'TRANSFER FROM A/C': 'Transfer In',\n",
        "    'SVG GIRO CR': 'Giro Credit',\n",
        "    'PRE-AUTH MYDEBIT': 'MyDebit Pre-Authorization',\n",
        "    'REV PREAUTH MYDEBIT': 'MyDebit Pre-Auth Reversal',\n",
        "    'IBK FUND TFR FRA/C': 'Fund Transfer Out (IBK) ',\n",
        "    'CASH WITHDRAWAL': 'Cash Withdrawal',\n",
        "    'FUND TRANSFER TO': 'Fund Transfer Out',\n",
        "    'MAS PAYMENT CREDIT': 'MAS Credit',\n",
        "    'PYMT FROM A/C': 'Payment from Account',\n",
        "    'IBK FUND TFR TO A/C': 'Fund Transfer Out (IBK)',\n",
        "    'FPOPRTREMETEAPO': 'Payment from Account',\n",
        "    'pviatstbpPA700100': 'Online Payment'\n",
        "}\n",
        "\n",
        "# Apply the replacements to the 'PaymentType' column\n",
        "merged_df['PaymentType'] = merged_df['PaymentType'].replace(payment_type_replacements)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "V-sf-JKvrEND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merchantname = merged_df['Merchant']\n",
        "merchantname.unique()"
      ],
      "metadata": {
        "id": "SNBexTxjlCYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of replacements\n",
        "merchant_replacements = {\n",
        "    'MALACCA SECURITIES S\\nWC': 'Malacca Securities',\n",
        "    'T': 'IPAY(88) SDN BHD',\n",
        "    'cuti': 'UNKNOWN',\n",
        "    'Perhation': 'UNKNOWN',\n",
        "    'Perhetion': 'UNKNOWN',\n",
        "    'MALACCA SECURITIES S\\n\\nWC': 'Malacca Securities',\n",
        "    'MCL': 'Malacca Securities',\n",
        "    'TTI NURUL HAIDAR B': 'SITI NURUL HAIDAR B',\n",
        "    'MALACCA SECURITIES': 'Malacca Securities',\n",
        "    'SITI NURUL': 'UNKNOWN',\n",
        "    'PUAN SITI NURUL HAT': 'UNKNOWN',\n",
        "    'ITI NURUL IDAYU BI': 'SITI NURUL IDAYU BI',\n",
        "    'MALACCA SECURITIES S\\nwe': 'Malacca Securities'\n",
        "}\n",
        "\n",
        "# Apply the replacements to the 'PaymentType' column\n",
        "merged_df['Merchant'] = merged_df['Merchant'].replace(merchant_replacements)\n",
        "merged_df"
      ],
      "metadata": {
        "id": "j8YW2_KqtTgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update online payment for payment type for foodpanda\n",
        "merged_df.loc[merged_df['PaymentType'] == 'Online Payment', 'Merchant'] = 'FOODPANDA MALAYSIA'\n",
        "merged_df"
      ],
      "metadata": {
        "id": "6fvFYTPWhxix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[merged_df['PaymentType'] == 'Stock Transaction', 'Merchant'] = 'Malacca Securities'\n",
        "merged_df"
      ],
      "metadata": {
        "id": "x6v4yc6KyerD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update fpx payment for payment type for foodpanda\n",
        "merged_df.loc[merged_df['PaymentType'] == 'MyDebit Payment', 'Merchant'] = 'UNKNOWN'"
      ],
      "metadata": {
        "id": "G_h7-J6Yywkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update fpx payment for payment type for foodpanda\n",
        "merged_df.loc[merged_df['PaymentType'] == 'Cash Withdrawal', 'Merchant'] = 'UNKNOWN'"
      ],
      "metadata": {
        "id": "0mS72nlxy-W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[merged_df['PaymentType'] == 'MyDebit Pre-Authorization', 'Merchant'] = 'PETRON SETIA ALAM'\n"
      ],
      "metadata": {
        "id": "MqCjev0zzIyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.loc[merged_df['PaymentType'] == 'MyDebit Pre-Auth Reversal', 'Merchant'] = 'PETRON SETIA ALAM'"
      ],
      "metadata": {
        "id": "VWd2vkjTzTgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named 'df'\n",
        "merged_df.to_csv('DATA 1.csv', index=False)"
      ],
      "metadata": {
        "id": "rHoBdw0shRmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA 2"
      ],
      "metadata": {
        "id": "O-v3qc530vVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# List of image file paths\n",
        "image_files = [\n",
        "    'jasin.jpg',\n",
        "    'jasin1.jpg',\n",
        "    'jasin2.jpg',\n",
        "    'jasin3.jpg',\n",
        "    'jasin4.jpg',\n",
        "    'jasin5.jpg'\n",
        "]\n",
        "\n",
        "# List to store extracted text from each image\n",
        "extracted_texts = []\n",
        "\n",
        "# Iterate over the list of image files\n",
        "for img_path in image_files:\n",
        "    # Open the image file\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Perform OCR on the image\n",
        "    text = pytesseract.image_to_string(img)\n",
        "\n",
        "    # Append the extracted text to the list\n",
        "    extracted_texts.append((img_path, text))\n",
        "\n",
        "# Print the extracted texts\n",
        "for img_path, text in extracted_texts:\n",
        "    print(f\"Text from {img_path}:\\n{text}\\n\")"
      ],
      "metadata": {
        "id": "yaXSnVz00z9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Define the pattern to extract transaction details, allowing for optional merchant name\n",
        "transaction_pattern = re.compile(\n",
        "    r'(\\d{2}/\\d{2}/\\d{2})\\s+\\|\\s+(.*?)\\s+([+-]?\\d{1,3}(,\\d{3})*(\\.\\d+)?)([+-])?\\s+([\\d,.]+)(\\n([A-Za-z\\s]+))?'\n",
        ")\n",
        "\n",
        "# Initialize a list to store extracted transactions\n",
        "transactions = []\n",
        "\n",
        "# Process each extracted text entry\n",
        "for img_path, extracted_text in extracted_texts:\n",
        "    # Use regex to find all matches\n",
        "    for match in transaction_pattern.finditer(extracted_text):\n",
        "        entry_date, description, amount, _, _, sign, balance, _, merchant = match.groups()\n",
        "\n",
        "        # Clean up the extracted data\n",
        "        amount = amount.replace(',', '')\n",
        "        balance = balance.replace(',', '')\n",
        "\n",
        "        # Determine debit or credit\n",
        "        debit = 0.0\n",
        "        credit = 0.0\n",
        "        if sign == '+':\n",
        "            credit = float(amount)\n",
        "        elif sign == '-':\n",
        "            debit = float(amount)\n",
        "        else:  # If no sign, assume debit\n",
        "            debit = float(amount)\n",
        "\n",
        "        # Notes: Any additional description from the main description field\n",
        "        notes = description.strip()\n",
        "\n",
        "        # If there's no merchant name captured, set it to \"UNKNOWN\"\n",
        "        merchant = merchant.strip() if merchant else \"UNKNOWN\"\n",
        "\n",
        "        # Append transaction details\n",
        "        transactions.append([entry_date, merchant, notes, debit, credit, float(balance)])\n",
        "\n",
        "# Create a DataFrame\n",
        "df_data2 = pd.DataFrame(transactions, columns=['Date', 'Merchant', 'PaymentType', 'Debit', 'Credit', 'Balance'])\n",
        "\n",
        "# Display the DataFrame\n",
        "df_data2\n"
      ],
      "metadata": {
        "id": "xtzUunZf07gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image\n",
        "img = cv2.imread('jasin6.jpg')\n",
        "\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Binarize the image\n",
        "_, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Remove horizontal lines\n",
        "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
        "remove_horizontal = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
        "\n",
        "# Remove vertical lines\n",
        "vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
        "remove_vertical = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
        "\n",
        "# Combine the two to get all table lines\n",
        "table_mask = cv2.add(remove_horizontal, remove_vertical)\n",
        "\n",
        "# Subtract lines from original binary to get clean text\n",
        "cleaned = cv2.bitwise_and(binary, binary, mask=cv2.bitwise_not(table_mask))\n",
        "\n",
        "# Invert to get final image for Tesseract\n",
        "final_img = cv2.bitwise_not(cleaned)\n",
        "\n",
        "# Optional: Show image\n",
        "plt.imshow(final_img, cmap='gray')\n",
        "plt.title(\"Cleaned for OCR\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save for OCR use\n",
        "cv2.imwrite('jasin6_cleaned.jpg', final_img)\n"
      ],
      "metadata": {
        "id": "yYZIV4Ut1Arv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform OCR on the preprocessed image\n",
        "extractedInformation3 = pytesseract.image_to_string(final_img)\n",
        "print(extractedInformation3)"
      ],
      "metadata": {
        "id": "iE3z4i1m1Mvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Define the pattern to extract transaction details, allowing for optional merchant name\n",
        "transaction_pattern = re.compile(\n",
        "    r'(\\d{1,2}/\\d{1,2}/\\d{2})\\s+[\\|_|]\\s+(.*?)\\s+([+-]?\\d{1,3}(,\\d{3})*(\\.\\d+)?)([+-])?\\s+([\\d,.]+)(\\n([A-Za-z\\s]+))?'\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize a list to store extracted transactions\n",
        "transactions = []\n",
        "\n",
        "# Use regex to find all matches\n",
        "for match in transaction_pattern.finditer(extractedInformation3):\n",
        "    entry_date, description, amount, _, _, sign, balance, _, merchant = match.groups()\n",
        "\n",
        "    # Clean up the extracted data\n",
        "    amount = amount.replace(',', '')\n",
        "    balance = balance.replace(',', '')\n",
        "\n",
        "    # Determine debit or credit\n",
        "    debit = 0.0\n",
        "    credit = 0.0\n",
        "    if sign == '+':\n",
        "        credit = float(amount)\n",
        "    elif sign == '-':\n",
        "        debit = float(amount)\n",
        "    else:  # If no sign, assume debit\n",
        "        debit = float(amount)\n",
        "\n",
        "    # Notes: Any additional description from the main description field\n",
        "    notes = description.strip()\n",
        "\n",
        "    # If there's no merchant name captured, set it to \"UNKNOWN\"\n",
        "    merchant = merchant.strip() if merchant else \"UNKNOWN\"\n",
        "\n",
        "    # Append transaction details\n",
        "    transactions.append([entry_date, merchant, notes, debit, credit, float(balance)])\n",
        "\n",
        "# Create a DataFrame\n",
        "df1_data2 = pd.DataFrame(transactions, columns=['Date', 'Merchant', 'PaymentType', 'Debit', 'Credit', 'Balance'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df1_data2)"
      ],
      "metadata": {
        "id": "07S7pckD1Tid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load image\n",
        "img2 = cv2.imread('jasin7.jpg')\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Binarize the image\n",
        "_, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Remove horizontal lines\n",
        "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
        "remove_horizontal = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
        "\n",
        "# Remove vertical lines\n",
        "vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
        "remove_vertical = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
        "\n",
        "# Combine the two to get all table lines\n",
        "table_mask = cv2.add(remove_horizontal, remove_vertical)\n",
        "\n",
        "# Subtract lines from original binary to get clean text\n",
        "cleaned = cv2.bitwise_and(binary, binary, mask=cv2.bitwise_not(table_mask))\n",
        "\n",
        "# Invert to get final image for Tesseract\n",
        "final_img2 = cv2.bitwise_not(cleaned)\n",
        "\n",
        "# Optional: Show image\n",
        "plt.imshow(final_img2, cmap='gray')\n",
        "plt.title(\"Cleaned for OCR\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Save for OCR use\n",
        "cv2.imwrite('jasin7_cleaned.jpg', final_img2)"
      ],
      "metadata": {
        "id": "Zv1XEA9P1FAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform OCR on the preprocessed image\n",
        "extractedInformation4 = pytesseract.image_to_string(final_img2)\n",
        "print(extractedInformation4)"
      ],
      "metadata": {
        "id": "lLtCY7rn1Pp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Define the pattern to extract transaction details, allowing for optional merchant name\n",
        "transaction_pattern = re.compile(\n",
        "    r'(\\d{1,2}/\\d{1,2}/\\d{2})\\s+[\\|_|]\\s+(.*?)\\s+([+-]?\\d{1,3}(,\\d{3})*(\\.\\d+)?)([+-])?\\s+([\\d,.]+)(\\n([A-Za-z\\s]+))?'\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize a list to store extracted transactions\n",
        "transactions = []\n",
        "\n",
        "# Use regex to find all matches\n",
        "for match in transaction_pattern.finditer(extractedInformation4):\n",
        "    entry_date, description, amount, _, _, sign, balance, _, merchant = match.groups()\n",
        "\n",
        "    # Clean up the extracted data\n",
        "    amount = amount.replace(',', '')\n",
        "    balance = balance.replace(',', '')\n",
        "\n",
        "    # Determine debit or credit\n",
        "    debit = 0.0\n",
        "    credit = 0.0\n",
        "    if sign == '+':\n",
        "        credit = float(amount)\n",
        "    elif sign == '-':\n",
        "        debit = float(amount)\n",
        "    else:  # If no sign, assume debit\n",
        "        debit = float(amount)\n",
        "\n",
        "    # Notes: Any additional description from the main description field\n",
        "    notes = description.strip()\n",
        "\n",
        "    # If there's no merchant name captured, set it to \"UNKNOWN\"\n",
        "    merchant = merchant.strip() if merchant else \"UNKNOWN\"\n",
        "\n",
        "    # Append transaction details\n",
        "    transactions.append([entry_date, merchant, notes, debit, credit, float(balance)])\n",
        "\n",
        "# Create a DataFrame\n",
        "df2_data2 = pd.DataFrame(transactions, columns=['Date', 'Merchant', 'PaymentType', 'Debit', 'Credit', 'Balance'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df2_data2)"
      ],
      "metadata": {
        "id": "PqbPKRa31ZWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the DataFrames\n",
        "merged_df1 = pd.concat([df_data2, df1_data2, df2_data2], ignore_index=True)\n",
        "\n",
        "merged_df1"
      ],
      "metadata": {
        "id": "_qVhzcU71dns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new column for person_id\n",
        "merged_df1['Person'] = 'B'"
      ],
      "metadata": {
        "id": "lbkurGp3lkPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df1.isna().sum()"
      ],
      "metadata": {
        "id": "RXLrg6iR1sSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df1['Date'] = pd.to_datetime(merged_df1['Date'])\n",
        "merged_df1"
      ],
      "metadata": {
        "id": "XmxKjtrK1v2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payment_types = merged_df1['PaymentType']\n",
        "payment_types.unique()"
      ],
      "metadata": {
        "id": "vXVByB-91wvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of replacements\n",
        "payment_type_replacements = {\n",
        "   'FUND TRANSFER TO A/': 'Fund Transfer Out',\n",
        "    'IBK FUND TFR FR A/C': 'Fund Transfer In (IBK)',\n",
        "    'IBK FUND TFR FRA/C': 'Fund Transfer In (IBK)',\n",
        "    'IBK FUND TFR TO A/C': 'Fund Transfer In (IBK)',\n",
        "    'TRANSFER FROM A/C': 'Transfer In',\n",
        "    'CASH DEPOSIT': 'Cash Deposit',\n",
        "    'HOUSE CHQ DEPOSIT': 'Cheque Deposit',\n",
        "    'CASH WITHDRAWAL': 'Cash Withdrawal',\n",
        "    'FPX PAYMENT FR A/': 'Online Payment',\n",
        "    'PAYMENT VIA MYDEBIT': 'MyDebit Payment',\n",
        "    'PYMT VIA MYDEBIT RE': 'MyDebit Refund',\n",
        "    'SVG GIRO CR': 'GIRO Credit',\n",
        "    'PYMT FROM A/C': 'Payment from Account',\n",
        "    'MAS PAYMENT CREDIT': 'Credit',\n",
        "    'SALE DEBIT': 'Sale Debit',\n",
        "    'DEBIT ADVICE': 'Debit Advice'\n",
        "}\n",
        "\n",
        "# Apply the replacements to the 'PaymentType' column\n",
        "merged_df1['PaymentType'] = merged_df1['PaymentType'].replace(payment_type_replacements)\n",
        "merged_df1"
      ],
      "metadata": {
        "id": "hyVnrjNc10Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merchantname = merged_df1['Merchant']\n",
        "merchantname.unique()"
      ],
      "metadata": {
        "id": "AuTnNBjs131R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of replacements\n",
        "merchant_replacements = {\n",
        "    'MUHAMMAD ALLIF ASYHR\\nFUND TRANSFER': 'MUHAMMAD ALLIF ASYHR',\n",
        "    'P': 'CELCOM POSTPAID PAYMENT',\n",
        "    'Perhation': 'SHOPPEE TOP UP',\n",
        "    'FAR EAST HOLDINGS BE\\nGAJI FEBRUARI': 'FAR EAST HOLDINGS BE',\n",
        "    'CAPY': 'CELCOM MOBILE SDN BHD',\n",
        "    'FAR EAST HOLDINGS BE\\nGAIL MAC': 'FAR EAST HOLDINGS BE',\n",
        "    'UNAS MANIA SUPERMA': 'TUNAS MANJA SUPERMARKET'\n",
        "}\n",
        "\n",
        "# Apply the replacements to the 'PaymentType' column\n",
        "merged_df1['Merchant'] = merged_df1['Merchant'].replace(merchant_replacements)\n",
        "merged_df1"
      ],
      "metadata": {
        "id": "ez-QaTCy17bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update online payment for payment type for foodpanda\n",
        "merged_df1.loc[merged_df1['PaymentType'] == 'Online Payment', 'Merchant'] = 'SHOPPEE'\n",
        "merged_df1"
      ],
      "metadata": {
        "id": "BoFauS-K1-eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named 'df'\n",
        "merged_df1.to_csv('DATA 2.csv', index=False)"
      ],
      "metadata": {
        "id": "juPWig7z2BwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge Data 1 and Data 2"
      ],
      "metadata": {
        "id": "ZDOJyU1oSeqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge datasets (optional: use inner if you want matching rows only)\n",
        "merged_data = pd.concat([merged_df, merged_df1], ignore_index=True)\n",
        "merged_data\n"
      ],
      "metadata": {
        "id": "B9h1ViJBSeRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "id": "9lQmLtR10xAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract month from 'Date'\n",
        "merged_df['Month'] = merged_df['Date'].dt.month\n",
        "merged_df1['Month'] = merged_df1['Date'].dt.month\n",
        "\n",
        "# Filter Dataset 1 for July (7) to September (9)\n",
        "df1_filtered = merged_df[merged_df['Month'].isin([7, 8, 9])]\n",
        "\n",
        "# Filter Dataset 2 for January (1) to March (3)\n",
        "df2_filtered = merged_df1[merged_df1['Month'].isin([1, 2, 3])]\n",
        "\n",
        "# Group and sum by actual month (to keep order)\n",
        "monthly_spending1 = df1_filtered.groupby('Month')['Debit'].sum().reindex([7, 8, 9])\n",
        "monthly_spending2 = df2_filtered.groupby('Month')['Debit'].sum().reindex([1, 2, 3])\n",
        "\n",
        "# Plotting - map both to generic Month 1 to Month 3\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot([1, 2, 3], monthly_spending1.values, marker='o', color='blue', label='July–September (Dataset 1)')\n",
        "plt.plot([1, 2, 3], monthly_spending2.values, marker='o', color='orange', label='January–March (Dataset 2)')\n",
        "\n",
        "# Formatting\n",
        "plt.title('Monthly Spending Trend (Debit) Comparison')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Debit Amount')\n",
        "plt.xticks([1, 2, 3], ['Month 1', 'Month 2', 'Month 3'])\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XgUsVinXL3bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly Spending Trend (Debit) limited to months 7, 8, and 9\n",
        "merged_df['Month'] = merged_df['Date'].dt.month  # Extract the month as an integer\n",
        "df_filtered = merged_df[merged_df['Month'].isin([7, 8, 9])]  # Filter only months 7, 8, and 9\n",
        "\n",
        "# Group by month and sum the debit transactions\n",
        "monthly_spending = df_filtered.groupby('Month')['Debit'].sum()\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "monthly_spending.plot(kind='line', marker='o', color='blue')\n",
        "plt.title('Monthly Spending Trend (Debit) - Months 7, 8, and 9')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Debit Amount')\n",
        "plt.xticks([7, 8, 9], ['July', 'August', 'September'])  # Custom x-ticks for months\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "VMvY_z3jwvEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly Spending Trend (Debit) limited to months 7, 8, and 9\n",
        "merged_df1['Month'] = merged_df1['Date'].dt.month  # Extract the month as an integer\n",
        "df_filtered = merged_df1[merged_df1['Month'].isin([1, 2, 3])]  # Filter only months 7, 8, and 9\n",
        "\n",
        "# Group by month and sum the debit transactions\n",
        "monthly_spending = df_filtered.groupby('Month')['Debit'].sum()\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "monthly_spending.plot(kind='line', marker='o', color='blue')\n",
        "plt.title('Monthly Spending Trend (Debit) - Months 1, 2, and 3')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Debit Amount')\n",
        "plt.xticks([1, 2, 3], ['January', 'February', 'March'])  # Custom x-ticks for months\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4RBXebVeMn2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merchant analysis (all data)\n",
        "\n",
        "top_merchants = merged_data.groupby('Merchant')['Debit'].sum().sort_values(ascending=False).head(10)\n",
        "top_merchants.plot(kind='bar', figsize=(10, 6), title='Top 10 Merchants by Spending')\n",
        "plt.xlabel('Merchant')\n",
        "plt.ylabel('Total Debit')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l9adZOBeNLFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merchant analysis (data 1)\n",
        "\n",
        "top_merchants = merged_df.groupby('Merchant')['Debit'].sum().sort_values(ascending=False).head(10)\n",
        "top_merchants.plot(kind='bar', figsize=(10, 6), title='Top 10 Merchants by Spending')\n",
        "plt.xlabel('Merchant')\n",
        "plt.ylabel('Total Debit')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7fgIZRM7jw7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merchant analysis (data 2)\n",
        "\n",
        "top_merchants = merged_df1.groupby('Merchant')['Debit'].sum().sort_values(ascending=False).head(10)\n",
        "top_merchants.plot(kind='bar', figsize=(10, 6), title='Top 10 Merchants by Spending')\n",
        "plt.xlabel('Merchant')\n",
        "plt.ylabel('Total Debit')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "To2qqjzDMU04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Already imported, but okay to keep\n",
        "\n",
        "# Get top 5 payment types\n",
        "payment_type_count = merged_data['PaymentType'].value_counts().head(5)\n",
        "\n",
        "# Create pie chart\n",
        "plt.figure(figsize=(8, 8))  # Square shape for pie\n",
        "colors = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854']  # Nice color palette\n",
        "\n",
        "plt.pie(payment_type_count, labels=payment_type_count.index, autopct='%1.1f%%', startangle=140, colors=colors)\n",
        "plt.title('Top 5 Payment Types by Transaction Count')\n",
        "plt.axis('equal')  # Ensure pie is a circle\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GFZdBrrvD5dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transaction Count by PaymentType - Top 10 (all data)\n",
        "import matplotlib.pyplot as plt  # Import the matplotlib.pyplot module and assign it the alias 'plt'\n",
        "\n",
        "payment_type_count = merged_data['PaymentType'].value_counts().head(10)  # Get top 10\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size for better visibility\n",
        "payment_type_count.plot(kind='bar', color=['skyblue', 'lightgreen'])\n",
        "plt.title('Transaction Count by PaymentType (Top 10)')\n",
        "plt.xlabel('Payment Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v25xyrRhNXbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Already imported, but okay to keep\n",
        "\n",
        "# Get top 5 payment types\n",
        "payment_type_count = merged_df['PaymentType'].value_counts().head(5)\n",
        "\n",
        "# Create pie chart\n",
        "plt.figure(figsize=(8, 8))  # Square shape for pie\n",
        "colors = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854']  # Nice color palette\n",
        "\n",
        "plt.pie(payment_type_count, labels=payment_type_count.index, autopct='%1.1f%%', startangle=140, colors=colors)\n",
        "plt.title('Top 5 Payment Types by Transaction Count')\n",
        "plt.axis('equal')  # Ensure pie is a circle\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-tc9DQuIEpj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Transaction Count by PaymentType - Top 10 (data 1)\n",
        "import matplotlib.pyplot as plt  # Import the matplotlib.pyplot module and assign it the alias 'plt'\n",
        "\n",
        "payment_type_count = merged_df['PaymentType'].value_counts().head(10)  # Get top 10\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size for better visibility\n",
        "payment_type_count.plot(kind='bar', color=['skyblue', 'lightgreen'])\n",
        "plt.title('Transaction Count by PaymentType (Top 10)')\n",
        "plt.xlabel('Payment Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5dVQtz5Z0a-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Already imported, but okay to keep\n",
        "\n",
        "# Get top 5 payment types\n",
        "payment_type_count = merged_df1['PaymentType'].value_counts().head(5)\n",
        "\n",
        "# Create pie chart\n",
        "plt.figure(figsize=(8, 8))  # Square shape for pie\n",
        "colors = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854']  # Nice color palette\n",
        "\n",
        "plt.pie(payment_type_count, labels=payment_type_count.index, autopct='%1.1f%%', startangle=140, colors=colors)\n",
        "plt.title('Top 5 Payment Types by Transaction Count')\n",
        "plt.axis('equal')  # Ensure pie is a circle\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vEHNJYv1Ez6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Transaction Count by PaymentType - Top 10 (data 2)\n",
        "import matplotlib.pyplot as plt  # Import the matplotlib.pyplot module and assign it the alias 'plt'\n",
        "\n",
        "payment_type_count = merged_df1['PaymentType'].value_counts().head(10)  # Get top 10\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size for better visibility\n",
        "payment_type_count.plot(kind='bar', color=['skyblue', 'lightgreen'])\n",
        "plt.title('Transaction Count by PaymentType (Top 10)')\n",
        "plt.xlabel('Payment Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nNWDvd51MaCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM AND K-MEANS"
      ],
      "metadata": {
        "id": "CqP0-IX_v-el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fE4Fsrka0niU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RFM metrics\n",
        "snapshot_date = merged_data['Date'].max() + pd.Timedelta(days=1)\n",
        "rfm = merged_df.groupby('Merchant').agg({\n",
        "    'Date': lambda x: (snapshot_date - x.max()).days,  # Recency\n",
        "    'PaymentType': 'count',                             # Frequency\n",
        "    'Debit': 'sum'                                   # Monetary (assuming 'debit' represents spend)\n",
        "}).reset_index()\n",
        "rfm.rename(columns={\n",
        "    'Date': 'Recency',\n",
        "    'PaymentType': 'Frequency',\n",
        "    'Debit': 'Monetary'\n",
        "}, inplace=True)"
      ],
      "metadata": {
        "id": "-KKcp6Z90ois"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Prepare RFM data (only for known merchants) for clustering\n",
        "rfm_features = rfm[['Recency', 'Frequency', 'Monetary']]"
      ],
      "metadata": {
        "id": "vl0oz6PAgl-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler  # Import MinMaxScaler\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the RFM features\n",
        "rfm_scaled = scaler.fit_transform(rfm_features)"
      ],
      "metadata": {
        "id": "JhPm6Tg7mTNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-Means\n",
        "# Determine the optimal number of clusters using the Elbow Method\n",
        "inertia = []\n",
        "# Change the range of k_values to be less than or equal to the number of samples\n",
        "k_values = range(1, 5)  # Assuming rfm_normalized has 8 samples or less\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(rfm_scaled)\n",
        "    inertia.append(kmeans.inertia_)"
      ],
      "metadata": {
        "id": "lD7z0vV10zQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Elbow Curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, inertia, marker='o')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4WtfejZ402br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit K-Means with optimal number of clusters\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)"
      ],
      "metadata": {
        "id": "cZuuyAmF07eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rfm)"
      ],
      "metadata": {
        "id": "b8zBmnr6eYDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Reduce dimensionality to 2D using PCA\n",
        "pca = PCA(n_components=2)\n",
        "rfm_pca = pca.fit_transform(rfm_scaled)\n",
        "\n",
        "# Plot the clusters\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(rfm_pca[:, 0], rfm_pca[:, 1], c=rfm['Cluster'], cmap='viridis', s=50, alpha=0.7)\n",
        "\n",
        "# Plot the centroids of the clusters\n",
        "centroids = pca.transform(kmeans.cluster_centers_)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('K-Means Clustering Visualization')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vjFpins21HX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the clusters, selecting only numeric columns for the mean calculation\n",
        "cluster_summary = rfm.groupby('Cluster')[['Recency', 'Frequency', 'Monetary']].mean()\n",
        "print(cluster_summary)"
      ],
      "metadata": {
        "id": "pYbdwe-I1LD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Evaluate the model using Silhouette Score\n",
        "# Get the cluster labels and the data used for clustering\n",
        "labels = rfm['Cluster']\n",
        "data_for_clustering = rfm[['Recency', 'Frequency', 'Monetary']]\n",
        "\n",
        "# Calculate the Silhouette Score\n",
        "silhouette_avg = silhouette_score(data_for_clustering, labels)\n",
        "print(f\"Silhouette Score: {silhouette_avg}\")"
      ],
      "metadata": {
        "id": "tdkQ3Dlc1bpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "anomaly detection"
      ],
      "metadata": {
        "id": "OtEzqWEw1mAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest"
      ],
      "metadata": {
        "id": "V2O48Rq-1pRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only numeric columns for scaling\n",
        "merged_data_numeric = merged_data.select_dtypes(include=[float, int])  # Select only numeric columns"
      ],
      "metadata": {
        "id": "T8jADJfw1s4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df_normalized = scaler.fit_transform(merged_data_numeric)  # Normalize the features"
      ],
      "metadata": {
        "id": "0Cnnecp91vaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Isolation Forest model\n",
        "iso_forest = IsolationForest(contamination=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "s_BkQMZm1yFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model and predict anomalies\n",
        "merged_data['Anomaly'] = iso_forest.fit_predict(df_normalized)"
      ],
      "metadata": {
        "id": "nfVSBiF-10Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Map the predictions: -1 = anomaly, 1 = normal\n",
        "merged_data['Anomaly'] = merged_data['Anomaly'].map({1: 'Normal', -1: 'Anomaly'})"
      ],
      "metadata": {
        "id": "KT4gfLHv12bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Reduce dimensionality to 2D using PCA for visualization\n",
        "pca = PCA(n_components=2)\n",
        "df_pca = pca.fit_transform(df_normalized)"
      ],
      "metadata": {
        "id": "F9rerlkf14n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Plot the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df_pca[:, 0], df_pca[:, 1], c=(merged_data['Anomaly'] == 'Anomaly'), cmap='coolwarm', s=50, alpha=0.7)\n",
        "\n",
        "# Add labels and title\n",
        "plt.title('Isolation Forest Anomaly Detection')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nOB3NVrp18ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Silhouette Score\n",
        "# Assuming 'Anomaly' column in merged_df contains anomaly predictions (Normal/Anomaly)\n",
        "# Map 'Anomaly' column to numeric values (e.g., 1 for Anomaly, 0 for Normal)\n",
        "predicted_anomalies = merged_data['Anomaly'].map({'Anomaly': 1, 'Normal': 0})\n",
        "silhouette_avg = silhouette_score(df_normalized, predicted_anomalies)\n",
        "print(f\"Silhouette Score: {silhouette_avg}\")"
      ],
      "metadata": {
        "id": "h61MVHxRl-sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data"
      ],
      "metadata": {
        "id": "xRP4KHEclj8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Anomaly column is labeled as 'anomaly'\n",
        "anomalies_only = merged_data[merged_data['Anomaly'] == 'Anomaly']\n",
        "\n",
        "# Display the result\n",
        "print(anomalies_only)"
      ],
      "metadata": {
        "id": "ykknk9yxUlT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named 'df'\n",
        "merged_data.to_csv('DATA with anomaly.csv', index=False)"
      ],
      "metadata": {
        "id": "KOwZTBSispxj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}